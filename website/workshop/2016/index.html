<!DOCTYPE HTML>
<!--
	Retrospect by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>

		<link rel="apple-touch-icon" sizes="57x57" href="images/favicons/apple-touch-icon-57x57.png">
		<link rel="apple-touch-icon" sizes="60x60" href="images/favicons/apple-touch-icon-60x60.png">
		<link rel="apple-touch-icon" sizes="72x72" href="images/favicons/apple-touch-icon-72x72.png">
		<link rel="apple-touch-icon" sizes="76x76" href="images/favicons/apple-touch-icon-76x76.png">
		<link rel="apple-touch-icon" sizes="114x114" href="images/favicons/apple-touch-icon-114x114.png">
		<link rel="apple-touch-icon" sizes="120x120" href="images/favicons/apple-touch-icon-120x120.png">
		<link rel="apple-touch-icon" sizes="144x144" href="images/favicons/apple-touch-icon-144x144.png">
		<link rel="apple-touch-icon" sizes="152x152" href="images/favicons/apple-touch-icon-152x152.png">
		<link rel="apple-touch-icon" sizes="180x180" href="images/favicons/apple-touch-icon-180x180.png">
		<link rel="icon" type="image/png" href="images/favicons/favicon-32x32.png" sizes="32x32">
		<link rel="icon" type="image/png" href="images/favicons/android-chrome-192x192.png" sizes="192x192">
		<link rel="icon" type="image/png" href="images/favicons/favicon-96x96.png" sizes="96x96">
		<link rel="icon" type="image/png" href="images/favicons/favicon-16x16.png" sizes="16x16">
		<link rel="manifest" href="images/favicons/manifest.json">
		<link rel="mask-icon" href="images/favicons/safari-pinned-tab.svg" color="#5bbad5">
		<link rel="shortcut icon" href="images/favicons/favicon.ico">
		<meta name="apple-mobile-web-app-title" content="Can We Build Baymax?">
		<meta name="application-name" content="Can We Build Baymax?">
		<meta name="msapplication-TileColor" content="#da532c">
		<meta name="msapplication-TileImage" content="images/favicons/mstile-144x144.png">
		<meta name="msapplication-config" content="img/favicons/browserconfig.xml">
		<meta name="theme-color" content="#ffffff">



		<title>Can we Build Baymax? Humanoids 2016</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main_orig.css" />
		<link rel="stylesheet" href="assets/css/override.css" />
		<link rel="stylesheet" href="assets/css/photos.css">
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->

		<!-- for facebook -->
		<meta property="og:url"                content="http://www.cs.cmu.edu/~cga/humanoids16workshop/" />
		<meta property="og:type"               content="article" />
		<meta property="og:title"              content="Can we Build Baymax? Humanoids 2016" />
		<meta property="og:description"        content="We are glad to announce that the full-day workshop 'Can We Build Baymax? Part 2. Making Hard Robots Soft: Sensors, Skin, and Airbags will be held on November 15, 2016, at IEEE-RAS International Conference on Humanoids Robots (Humanoids 2016), Cancun, Mexico. We invite you to contribute and to participate in this workshop."/>
		<meta property="og:image"              content="images/facebook/banner.jpg" />




	</head>
	<body class="landing">

		<!-- Header -->
			<header id="header" class="alt">
				<!--<div class="bighero-font"><a href="index.html">Humanoids2016</a></div>-->
				<h1><a href="#top">Humanoids 2016</a></h1>
				<!--<a href="index.html" class="position: absolute; display: inline-block; left: 1.25em; margin: 0; padding: 0;">Humanoids2016</a> -->
				<a href="#nav">Menu</a>
			</header>

		<!-- Nav -->
			<nav id="nav">
				<ul class="links">
					<li><a href="#top">Top</a></li>
					<!-- <li><a href="#call">Call for Contribution</a></li> -->
					<li><a href="#abstract">Abstract</a></li>
					<li><a href="#schedule">Schedule</a></li>
					<li><a href="#speakers">Speakers</a></li>
					<li><a href="#organizers">Organizers</a></li>
					<li><a href="#links">Related Links</a></li>
					<li><a href="#contact">Contact</a></li>
					<li><a href="photos.html">Photos</a></li>
					
				</ul>
			</nav>

		<!-- Banner -->
		<span class="anchor" id="top"></span>
			<section id="banner">
				<!--<i class="icon fa-diamond"></i>-->
				<div id="WSTitle">
					<div class="bighero-font">Can We Build</div>
					<div class="bighero-font">Baymax?</div>
				</div>
				<p>Part 2: Making Hard Robots Soft<br>Sensors, Skin and Airbags</p>
				<p>Cancun, Mexico
				<br>Nov. 15, 2016</p> 
				<ul class="actions">
					<li><a href="photos.html" class="button big special">Photos</a></li>
				</ul>


			<div id="baymax"><img style="height: 100%;" src="images/baymax/baymax.png" /></div>


			</section>






		<!--

		<div id="redbar"></div>
		<span class="anchor" id="call"></span>

		<section id="one" class="wrapper style2">

			<div class="inner">

				<h2><strong>Call For Contribution</strong></h2>
				<p>Dear Colleagues,</p>
 
				<p>We are glad to announce that the full-day workshop "Can We Build Baymax? Part 2. Making Hard Robots Soft: Sensors, Skin, and Airbags" will be held on November 15, 2016, at IEEE-RAS International Conference on Humanoids Robots (<a target="_blank" href="http://www.humanoids2016.org/">Humanoids 2016</a>), Cancun, Mexico. We invite you to contribute and to participate in this workshop.</p>

				<br>
 
				<p>The workshop's topics include, but are not limited to:</p>
				<ul>
					<li>Proprioceptive and exteroceptive sensors (tactile/force/proximity/whole-body vision)</li>
					<li>Inflatable skin and airbags</li>
					<li>Soft mechanisms for physical human-robot interaction</li>
					<li>Human-friendly humanoid design and implementation</li>
					<li>Self recovery/healing technology for robots</li>
				</ul>
				

				<br><br>

				<h2><strong>Abstract Submission</strong></h2>

				<p>The workshop will host an interactive poster session. The presenters in this session will be given the opportunity for an hour-long interactive poster presentation including a 3-minute spotlight pitch talk.</p>
 
 				<br>

				<p>Important dates:</p>
				<ul>	
					<li>October 16, 2016: Submissions due</li>
					<li>October 23, 2016: Acceptance notification</li>
					<li>November 15, 2016: Workshop</li>
				</ul>
				<br>

				<p>To participate, please submit an abstract (1-2 pages, double-column, PDF) via email to <br>
					Joohyung Kim ( joohyung.kim at disneyresearch dot com ) or <br>
					Jinoh Lee ( jinoh.lee at iit dot it )</p>

				<br>

				<p>Submission templates: <br>
				<a target="_blank" href="http://ras.papercept.net/conferences/support/tex.php">LaTeX</a>, <a target="_blank" href="http://ras.papercept.net/conferences/support/word.php">MS Word</a></p>
				
			</div>
		</section>

		<div id="redbar"></div>


		-->










		<!-- One -->
		<span class="anchor" id="abstract"></span>
		<section id="one" class="wrapper style1">
			<div class="inner">

				<h2><strong>Abstract</strong></h2>
				<p>This will be the 2nd workshop entitled “Can we build Baymax?”. The 1st workshop was held at Humanoids 2015 in Korea. Baymax is the soft humanoid character in Disney's feature animation "Big Hero 6." It is a healthcare robot with an inflatable body, capable of walking, bumping into surrounding objects and physically interacting with people. However, in the real world, it is not an easy robot to build. For the realization of this robot, awareness of the environment, especially a sense of touch and vision, is very important. Covering robots with soft material to protect both humans and the robot is also required. Integrating these features into actual hardware using reasonable fabrication methods is a challenging task. In this workshop, we will discuss topics related to building robots like Baymax with special features including but not limited to implementation of skin sensors, methods to protect humans and robots, and fabrication of soft skin for humanoids.</p>

				<!--
				<br>
				<p>The workshop's topics include, but are not limited to:</p>
				<ul>
					<li> Safe human-robot interactions </li>
					<li> Force and Torque control on joints and limbs </li>
					<li> Compliant joint mechanisms </li>
					<li> Inflatable body structures </li>
					<li> Soft skin sensors </li>
					<li> Muscle actuators </li>
				</ul>
				-->


				
			</div>
		</section>

		<!-- Two -->
		<span class="anchor" id="schedule"></span>
		<section id="two" class="wrapper style2">
			<div class="inner">

				<h2><strong>Schedule</strong></h2>
				



				<table class="schedule" width="100%" border="0" cellspacing="0" cellpadding="0">
					<tbody>

						<tr>
							<td class="sched_time">09:00 - 09:30</td>
							<td class="sched_speaker">Introduction by the Organizers</td>
						</tr>

						<tr>
							<td class="sched_time">09:30 - 10:00</td>
							<td class="sched_speaker">Chris Atkeson
								<div class="talk-title">Optical Robot Skin and Whole Body Vision</div>
		
							  	<div class="text-content short-text">
	        					One way to achieve high resoution tactile sensing is to use imaging to measure skin deformation. If the skin if fully transparent, it is also to possible to image nearby objects and provide a "proximity" sense which builds a map of nearby objects and surfaces. This talk describes first attempts at implementing optical skin for soft robots.
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>

							</td>
						</tr>

						<tr>
							<td class="sched_time">10:00 - 10:30</td>
							<td class="sched_speaker">Gordon Cheng
								<div class="talk-title">Making Hard Robots Actively Soft</div>
								
							  	<div class="text-content short-text">
	        					Conversational robots are hard and unsafe for real physical interactions -  and not soft. Although efforts with joint force/torque control have introduced a way to interact with robots, thus yielding a level of compliance to robots – which makes them a bit softer. In our latest works, we offer yet another level of compliance to robots, providing softness at the surface level – making them actively soft. In this talk, I will present our works through all the stages of creating this new level of surface soft controls.
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>
								
							</td>
						</tr>

						<tr>
							<td class="sched_time">10:30 - 11:00</td>
							<td class="sched_speaker">Coffee Break</td>
						</tr>

						<tr>
							<td class="sched_time">11:00 - 11:30</td>
							<td class="sched_speaker">Hee Sup Shin
								<div class="talk-title">Toward A Soft Sensor Skin</div>
								
							  	<div class="text-content short-text">
	        					In this talk, we introduce two different soft sensors, tactile and strain sensors. Both sensors were microfabricated using soft materials, resulting in compact sized sensors with high dynamic ranges. The design, fabrication, and characterization of the sensors will be presented in detail. In addition, two different methods to fabricate a soft skin will be introduced: integrating the strain sensors in a skin and manufacturing large area skins using a computerized numerical control (CNC) milling.
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>
								
							</td>
						</tr>

						<tr>
							<td class="sched_time">11:30 - 12:00</td>
							<td class="sched_speaker">Rudan János
								<div class="talk-title">OptoForce Multi-Axis Force and Torque Sensors to be used in Humanoid Robots</div>
								
							  	<div class="text-content short-text">
	        					As humanoid robots are achieving higher and higher complexity, the application of force and torque sensing is going to have crucial role on multiple levels. Multi-axis force sensors integrated into the feet can serve essential feedbacks about the layout of the ground, the ground-robot contact and the balance of the robot. Torque sensors applied in the joints can be used to have sensorial inputs about the body position and the execution of the planned movements. Small, sensitive force sensors in the hand and fingers of the robot can increase it's capability to interact with the environment properly. In the talk we are going to cover these applications of multi-axis force/torque sensing and we will see how OptoForce sensors can be applied in any of these setups. 
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>
								
							</td>
						</tr>

						<tr>
							<td class="sched_time">12:00 - 12:30</td>
							<td class="sched_speaker">Akihiko Yamaguchi
								<div class="talk-title">Optical Soft Skin For Soft Object Manipulation</div>
								
							  	<div class="text-content short-text">
	        					Recently our research challenge is robot cooking. Robotics technologies for handling cooking need to go beyond rigid object manipulation. Robot cooking involves many different types of manipulation, such as deformable (soft) object, chemical and thermal processes. We are taking a skill-library approach where we have many different strategies (skills) for handling difficult manipulation; for example tipping, shaking, and squeezing skills for pouring. Selection of skills and adjustment of skill parameters are done with model-based reinforcement learning. One big challenge is increasing the sensing capability. With lack of sensors, generating behaviors become much harder. We are proposing whole-body vision. In this talk, we focus on a specific version, optical skin for robot fingers. The optical skin is a camera-based tactile sensor that perceives tactile information (force field) and proximity vision. This multimodality is useful in soft object manipulation. Related papers and videos are available at <a target="_blank" href="http://www.akihikoy.net">akihikoy.net</a>
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>
								
							</td>
						</tr>

						<tr>
							<td class="sched_time">12:30 - 14:00</td>
							<td class="sched_speaker">Lunch</td>
						</tr>

						<tr>
							<td class="sched_time">14:00 - 14:30</td>
							<td class="sched_speaker">Shuuji Kajita
								<div class="talk-title">Fall Experiments of a Humanoid Robot HRP-2 Kai with an Airbag</div>
								
							  	<div class="text-content short-text">
	        					In this talk, we explain some technical details related to "Impact Acceleration of Falling Humanoid Robot with Airbag" which will be presented in the conference of Humanoids 2016. Preliminary experiments using commercial shock absorbing materials, and the comparison with another airbag system will be discussed.
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>
								
							</td>
						</tr>

						<tr>
							<td class="sched_time">14:30 - 15:00</td>
							<td class="sched_speaker">Marc Killpack
								<div class="talk-title">Soft Robot Variable Stiffness Control, Failure Mitigation, and Tactile Sensor Design</div>
								
							  	<div class="text-content short-text">
	        					Soft robots have the potential of changing the way that robots interact with the world and humans because of their low-inertia and potential low-cost. In this workshop talk, I will focus on our recent results in being able to simultaneously control position and stiffness of an antagonistic, pneumatically-actuated, soft robot joint. I will also present results on how varying stiffness can increase the operational life time of a soft pneumatic robot with a leak without directly sacrificing end effector accuracy. Finally, I will present our basic design for a tactile sensing grid that is easy to manufacture and integrate with soft robots.
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>
								
							</td>
						</tr>

						<tr>
							<td class="sched_time">15:00 - 15:30</td>
							<td class="sched_speaker">Jinoh Lee
								<div class="talk-title">Development of Modular and Active Impact Protection System for Humanoids Falling</div>
								
							  	<div class="text-content short-text">
	        					In this talk, we demonstrate a newly developed active-soft impact protection system specialized for humanoids, where a soft inflating vessel design, which is suitable to be used in the impact reduction mechanism, is incorporated with a miniaturized active pressure control unit with on-off solenoid valves. Owing to its modular design strategy, the developed impact protection system may be applied to a variety of practical humanoid robots. As a preliminary case study, the soft -inflating vessel is designed to be implemented on hands of a humanoid robot WALK-MAN. Details of the design, fabrication, experimental verification, and falling experiments will be covered.
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>
								
							</td>
						</tr>

						<tr>
							<td class="sched_time">15:30 - 16:00</td>
							<td class="sched_speaker">Coffee Break</td>
						</tr>

						<tr>
							<td class="sched_time">16:00 - 16:30</td>
							<td class="sched_speaker">Masayuki Inaba
								<div class="talk-title">TBD</div>
								<!--
							  	<div class="text-content short-text">
	        					Abstract text here
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>
								-->
							</td>
						</tr>

						<tr>
							<td class="sched_time">16:30 - 17:00</td>
							<td class="sched_speaker">Joohyung Kim
								<div class="talk-title">Towards Huggable Robots</div>
								
							  	<div class="text-content short-text">
	        					In this talk, we show our efforts to implement huggable robots. It'll include the design and fabrication of our soft skins and our hugging study with children. We will also present a new arm and hand system, which is covered with air bags for soft interaction.
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>
								
							</td>
						</tr>

						<tr>
							<td class="sched_time">17:00 - 18:00</td>
							<td class="sched_speaker">Closing Discussion 
							</td>
						</tr>

					</tbody>
					
				</table>



			</div>
		</section>	

		<!-- Three -->
		<span class="anchor" id="speakers"></span>
		<section id="three" class="wrapper style3">
			<div class="inner">

				<h2><strong>Speakers</strong></h2>


				<ul>
					<li><a href="#org_cheng">Gordon Cheng</a>, Technical University of Munich</li>
					<li><a href="#org_inaba">Masayuki Inaba</a>, University of Tokyo</li>
					<li><a href="#org_kajita">Shuuji Kajita</a>, National Institute of Advanced Industrial Science and Technology</li>
					<li><a href="#org_killpack">Marc Killpack</a>, Brigham Young University</li>
					<li><a href="#org_rudan">János Rudan</a>, OptoForce</li>
					<li><a href="#org_shin">Hee-Sup Shin</a>, University of Maryland</li>
					<li><a href="#org_yamaguchi">Akihiko Yamaguchi</a>, Carnegie Mellon University</li>
				</ul>

				<br>




				<span class="anchor2" id="org_cheng"></span>
				<article class="feature left">
					<span class="image"><img src="images/speakers/web/Cheng_Gordon.jpg" alt="" /></span>
					<div class="content">

						<h2>Gordon Cheng</h2>

						<!-- <h3>9:00 - 9:45</h3> -->
						<!-- <h2>Gordon Cheng<br>
						Design of a Soft Upper Body Robot for Physical Human-Robot Interaction</h2> -->

						<p>Gordon Cheng holds the Chair of Cognitive Systems with regular teaching activities and lectures. He is Founder and Director of Institute for Cognitive Systems, Faculty of Electrical and Computer Engineering at Technical University of Munich, Munich/Germany. He is also the coordinator of the CoC for Neuro-Engineering - Center of Competence Neuro-Engineering in the Department of Electrical and Computer Engineering.</p>
						
						<p>Formerly, he was the Head of the Department of Humanoid Robotics and Computational Neuroscience, ATR Computational Neuroscience Laboratories, Kyoto, Japan. He was the Group Leader for the newly initiated JST International Cooperative Research Project (ICORP), Computational Brain. He has also been designated as a Project Leader/Research Expert for National Institute of Information and Communications Technology (NICT) of Japan. He is also involved (as an adviser and as an associated partner) in a number of major European Union Projects.</p>
						
						<p>Over the past ten years Gordon Cheng has been the co-inventor of approximately 20 patents and is the author of approximately 250 technical publications, proceedings, editorials and book chapters.</p>

					</div>
				</article>		


				<span class="anchor2" id="org_inaba"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Inaba_Masayuki.jpg" alt="" /></span>
					<div class="content">

						<h2>Masayuki Inaba</h2>

						<p>Masayuki Inaba is a Professor at the Department of Creative Informatics in the Graduate School of Information Science and Technology, The University of Tokyo.  He graduated from the department of Mechanical Engineering at the University of Tokyo in 1981, and received M.S. and Ph.D. degrees from the graduate school of Information Engineering at The University of Tokyo in 1983 and 1986 respectively. He was appointed as a lecturer in the Department of Mechanical Engineering at The University of Tokyo in 1986, an associate professor in 1989, and a professor in the Department of Mechano-Informatics in 2000, and also a professor in new Department of Creative Informatics from 2005. He is directing the JSK Robotics Lab at The University of Tokyo.  His research interests include key technologies of robotic systems and software architectures to advance robotics research. His research projects have included hand-eye coordination in rope handling, vision-based robotic server system, remote-brained robot approach, whole-body behaviors in humanoids, robot sensor suit with electrically conductive fabric, flexible spined humanoid and developmental JSK mother projects with the remote-brained system environment, life-size assistive humanoids, musculoskeletal spined humanoid series, whole-body soft sensor tissues, IRT home assitance with personal mobility, open-source robotics middlewares, high speed-and-powered legs for the next generation humanoid.</p>

					</div>
				</article>


				<span class="anchor2" id="org_kajita"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Kajita_Shuuji.jpg" alt="" /></span>
					<div class="content">

						<h2>Shuuji Kajita</h2>

						<p>Received M.E. (1985) and Dr.E. (1996) degrees in control engineering from Tokyo Institute of Technology, Japan. In 1985, I joined the Mechanical Engineering Laboratory, Ministry of International Trade and Industry. Meanwhile I was a Visiting Researcher at California Institute of Technology, 1996-1997. Currently I am a senior researcher at the National Institute of Advanced Industrial Science and Technology, Tsukuba, Japan, which was reorganized from AIST-MITI in April 2001. My research interests include robotics and control theory. I am a member of Society of Instrument and Control Engineers, Robotics Society of Japan and IEEE (Robotics and Automation Society).</p>

					</div>
				</article>

				<span class="anchor2" id="org_killpack"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Killpack_Marc.jpg" alt="" /></span>
					<div class="content">

						<h2>Marc Killpack</h2>

						<p>Marc Killpack is an assistant professor in the department of Mechanical Engineering at Brigham Young University (BYU) since 2013. His lab was awarded a NASA Early Career Faculty award which has funded their research on soft robots. His current research interests relate to improving modeling and control for robot manipulation in unstructured and dynamic environments. This includes applications to space exploration, search and rescue, disaster response and human-robot interaction. Marc completed his Ph.D. in Robotics from the Healthcare Robotics Lab (HRL) at the Georgia Institute of Technology. Prior to joining HRL, Marc completed Masters’ degrees in Mechanical Engineering in 2008 from both Georgia Tech and AM ParisTech (formerly ENSAM) in Metz, France. In 2007, Marc graduated with a Bachelor of Science in Mechanical Engineering from Brigham Young University.</p>

					</div>
				</article>


				<span class="anchor2" id="org_rudan"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Rudan_Janos.jpg" alt="" /></span>
					<div class="content">

						<h2>János Rudan</h2>

						<p>János Rudan is a product consultant at OptoForce. He holds an MSc in robotics and a PhD in computer science. He is with OptoForce since 2014. He is an expert in multi-axial force and force/torque sensing, robotics and computer based control.</p>

					</div>
				</article>


				<span class="anchor2" id="org_shin"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Shin_HeeSup.jpg" alt="" /></span>
					<div class="content">

						<h2>Hee-Sup Shin</h2>

						<p>Hee-Sup Shin received the B.S. degree in mechanical engineering from Korea University, Seoul, South Korea, in 2013 and the M.S. degree in mechanical engineering from Carnegie Mellon University, Pittsburgh, PA, USA in 2015. He is currently pursuing the Ph.D degree in mechanical engineering at University of Maryland, College Park, MD, USA.  His research interests include smart materials for sensors, development of soft sensors for small-scale robots, and design of sensing skins for aircrafts.</p>

					</div>
				</article>


				<span class="anchor2" id="org_yamaguchi"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Yamaguchi_Akihiko.jpg" alt="" /></span>
					<div class="content">

						<h2>Akihiko Yamaguchi</h2>

						<p>Akihiko Yamaguchi received the BE degree from the Kyoto University, Kyoto, Japan, in 2006, and the ME and the PhD degrees from Nara Institute of Science and Technology (NAIST), Nara, Japan, in 2008 and 2011, respectively. From April 2010 to July in 2011, he was with NAIST as a JSPS, Japan Society for the Promotion of Science, Research Fellow. From August 2011 to March 2015, he was with NAIST as an Assistant Professor of the Robotics Laboratory in the Graduate School of Information Science. From April 2014 to March 2015, he was a visiting scholar of Robotics Institute in Carnegie Mellon University, and from April 2015 to present, he is a postdoctoral fellow of the same institute. His research interests include robot learning, reinforcement learning, artificial intelligence, and manipulation of deformable objects especially pouring.</p>

						<p><a target="_blank" href="http://www.akihikoy.net">akihikoy.net</a></p>

					</div>
				</article>


			</div>
		</section>

		<!-- Four -->
		<span class="anchor" id="organizers"></span>
		<section id="four" class="wrapper style1">
			<div class="inner">

				<h2><strong>Organizers</strong></h2>

				
				<ul>
					<li><a href="#org_atkeson">Chris Atkeson</a>, Carnegie Mellon University</li>
					<li><a href="#org_kim">Joohyung Kim</a>, Disney Research</li>
					<li><a href="#org_lee">Jinoh Lee</a>, Istituto Italiano di Tecnologia</li>
					<li><a href="#org_yamane">Katsu Yamane</a>, Disney Research</li>
				</ul>

				<br>

				<span class="anchor2" id="org_atkeson"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Atkeson_Chris.jpg" alt="" /></span>
					<div class="content">

						<h2>Christopher G. Atkeson</h2>

						<p>I am a Professor in the Robotics Institute and Human-Computer Interaction Institute at CMU. I received the M.S. degree in Applied Mathematics (Computer Science) from Harvard University and the Ph.D. degree in Brain and Cognitive Science from M.I.T. I joined the M.I.T. faculty in 1986, moved to the Georgia Institute of Technology College of Computing in 1994, and moved to CMU in 2000. I have received an NSF Presidential Young Investigator Award, a Sloan Research Fellowship, and a Teaching Award from the MIT Graduate Student Council.</p>

						<p><a target="_blank" href="http://www.build-baymax.org">build-baymax.org</a></p>

					</div>
				</article>

				<span class="anchor2" id="org_kim"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Kim_Joohyung.jpg" alt="" /></span>
					<div class="content">

						<h2>Joohyung Kim</h2>

						<p>Joohyung Kim is currently an Associate Research Scientist in Disney Research, Pittsburgh. His research interests include implementation of robots based on animation characters, soft human-robot interaction, balancing and walking control for humanoid robots and novel mechanisms for legged locomotion. He received BSE and Ph.D. degrees in Electrical Engineering and Computer Science from Seoul National University, Korea, in 2001 and 2012. Prior to joining Disney Research, he was a postdoctoral fellow in Robotics Institute of Carnegie Mellon University for DARPA Robotics Challenge in 2013. From 2009 to 2012 he was a senior engineer in Samsung Electronics, Korea, developing biped walking controllers for humanoid robots.</p>

					</div>
				</article>	

				<span class="anchor2" id="org_lee"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Lee_Jinoh.jpg" alt="" /></span>
					<div class="content">

						<h2>Jinoh Lee</h2>

						<p>Jinoh Lee was born in Seoul, South Korea. He received the B.Sc. degree in mechanical engineering from Hanyang University, Seoul, South Korea, in 2003 (awarded Top 2% Academic Excellence) and the M.Sc. and the Ph.D. degrees in Mechanical Engineering from Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea, in 2012. Since 2012, he has joined the Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Genoa, Italy, as a postdoctoral researcher, and was awarded a competitive grant from the National Research Foundation (NRF) of Korean Government, titled as ‘Fostering next generation researchers program’ from 2013-2014.</p>

						<p>He is currently a Senior Postdoctoral Researcher involved in projects such as Safe and Autonomous Physical Human-Aware Robot Interaction (SAPHARI) and Whole-body Adaptive Locomotion and Manipulation (WALK-MAN) funded under the European Community's 7th Framework Programme. In particular, he is a team member of WALK-MAN participating to final DARPA Robotics Challenge (DRC) on 5-6 June, 2015, Pomona USA, where contributions have been made to develop various manipulation skills on the humanoid. His research has been concerned with whole body manipulation of humanoid robots, compliant robotic system control for safe human-robot interaction, dual-arm dexterous manipulation, robust control of highly nonlinear systems, and smart and soft actuators. Since 2014, Dr. Lee has participated in Technical Committee member of International Federation of Automatic Control (IFAC), TC4.3 Robotics. He is also a member of IEEE Robotics and Automation, Control Systems, and Industrial Electronics Societies and the Program Committee of 2016 IEEE International Conference on Robotics and Biomimetics (ROBIO).</p>

					</div>
				</article>

				<span class="anchor2" id="org_yamane"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Yamane_Katsu.jpg" alt="" /></span>
					<div class="content">

						<h2>Katsu Yamane</h2>

						<p>Dr. Katsu Yamane is a Senior Research Scientist at Disney Research. He received his PhD in mechanical engineering from University of Tokyo in 2002.  Prior to joining Disney in 2008, he was a postdoctoral fellow at Carnegie Mellon University and a faculty member at University of Tokyo.  His research interests include humanoid robot control and motion synthesis, physical human-robot interaction, character animation, and human motion simulation.</p>

					</div>
				</article>	


				<!-- Logos -->
				<div class="logo_container2">
					<center>
					<img class="org_logos2 object-fit_contain" src="images/logos/web/logos2.png" alt="" />
					</center>
				</div>

				
			</div>
		</section>

		<!-- Five -->
		<span class="anchor" id="links"></span>
		<section id="five" class="wrapper style2">
			<div class="inner">

				<h2><strong>Related Links</strong></h2>

				
				<ul>
					<li><a target="_blank" href="http://www.humanoids2016.org/">Humanoids 2016</a></li>
					<li><a target="_blank" href="http://www.cs.cmu.edu/~cga/humanoids15workshop/">Can we Build Baymax? Humanoids 2015</a></li>
					<li><a target="_blank" href="http://www.build-baymax.org">Build-Baymax.org</a></li>
				</ul>
				
			</div>
		</section>

		<!-- Five -->
		<span class="anchor" id="contact"></span>
		<section id="five" class="wrapper style1">
			<div class="inner">

				<h2><strong>Contact</strong></h2>

				
				<ul>
					<li>Joohyung Kim ( joohyung.kim at disneyresearch dot com )</li>
					<li>Jinoh Lee ( jinoh.lee at iit dot it )</li>
				</ul>
				
			</div>
		</section>		






		<!-- Footer -->
		<footer id="footer">
			<div class="inner">
				<p><a href="http://alexalspach.com">Designed by Alex Alspach. 2016</a></p>
				
			</div>
		</footer>

		<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/skel.min.js"></script>
		<script src="assets/js/util.js"></script>
		<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
		<script src="assets/js/main.js"></script>


		<script>
			$(".show-more a").each(function() {
			    var $link = $(this);
			    var $content = $link.parent().prev("div.text-content");

			    console.log($link);

			    var visibleHeight = $content[0].clientHeight;
			    var actualHide = $content[0].scrollHeight - 1;

			    console.log(actualHide);
			    console.log(visibleHeight);

			    if (actualHide > visibleHeight) {
			        $link.show();
			    } else {
			        $link.hide();
			    }
			});

			$(".show-more a").on("click", function() {
			    var $link = $(this);
			    var $content = $link.parent().prev("div.text-content");
			    var linkText = $link.text();

			    $content.toggleClass("short-text, full-text");

			    $link.text(getShowLinkText(linkText));

			    return false;
			});

			function getShowLinkText(currentText) {
			    var newText = '';

			    if (currentText.toUpperCase() === "ABSTRACT") {
			        newText = "Hide Abstract";
			    } else {
			        newText = "Abstract";
			    }

			    return newText;
			}
		</script>




	</body>
</html>




