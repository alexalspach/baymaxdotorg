<!DOCTYPE HTML>
<!--
	Retrospect by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->

<html>
	<head>

		<!-- realfavicongenerator.net -->
		<link rel="apple-touch-icon" sizes="180x180" href="images/favicons/green/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="images/favicons/green/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="images/favicons/green/favicon-16x16.png">
		<link rel="manifest" href="images/favicons/green/site.webmanifest">
		<link rel="mask-icon" href="images/favicons/green/safari-pinned-tab.svg" color="#0f1524">
		<link rel="shortcut icon" href="images/favicons/green/favicon.ico">
		<meta name="apple-mobile-web-app-title" content="CWBB? 2019">
		<meta name="application-name" content="CWBB? 2019">
		<meta name="msapplication-TileColor" content="#da532c">
		<meta name="msapplication-config" content="images/favicons/green/browserconfig.xml">
		<meta name="theme-color" content="#ffffff">



		<title>Can we build Baymax? Humanoids 2019</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<!-- <link rel="stylesheet" href="assets/css/main_orig.css" /> -->
		<link rel="stylesheet" href="assets/css/main_orig.css" />
		<link rel="stylesheet" href="assets/css/override.css" />
		<link rel="stylesheet" href="assets/css/photos.css">
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->

		<!-- for facebook -->
		<meta property="og:url"                content="http://www.cs.cmu.edu/~cga/humanoids19workshop/" />
		<meta property="og:type"               content="article" />
		<meta property="og:title"              content="Can we build Baymax? Humanoids 2019" />
		
		<meta property="og:description"        content="We are excited to announce that the full-day workshop 'Can We Build Baymax? Part 5. Human-Humanoid Communication' will be held on October 15th, 2019 at IEEE-RAS International Conference on Humanoid Robots (Humanoids 2019) in Toronto, Canada. We invite you to contribute and to participate in this workshop."/>
		
		<meta property="og:image"              content="images/facebook/banner.jpg" />

	</head>



	<body class="landing">

		<!-- Header -->
			<header id="header" class="alt">
				<!--<div class="bighero-font"><a href="index.html">Humanoids2017</a></div>-->
				<h1><a href="#top">Humanoids 2019</a></h1>
				<!--<a href="index.html" class="position: absolute; display: inline-block; left: 1.25em; margin: 0; padding: 0;">Humanoids2017</a> -->
				<a href="#nav">Menu</a>
			</header>

		<!-- Nav -->
			<nav id="nav">
				<ul class="links">
					<li><a href="#top">Top</a></li>
					<!-- <li><a href="#call">Call for Contributions</a></li>-->
					<li><a href="#objectives">Objectives</a></li> 
					<li><a href="#schedule">Schedule</a></li>
					<li><a href="#speakers">Speakers</a></li>
					<li><a href="#organizers">Organizers</a></li>
					<li><a href="#links">Related Links</a></li>
					<li><a href="#contact">Contact</a></li>
					<!--<li><a href="photos.html">Photos</a></li>-->
					
				</ul>
			</nav>

		<!-- Banner -->
		<span class="anchor" id="top"></span>
			<section id="banner">
				<!--<i class="icon fa-diamond"></i>-->
				<div id="WSTitle">
					<div class="bighero-font">Can we build</div>
					<div class="bighero-font">Baymax?</div>
				</div>
				<p><strong>Part 5: Human-Humanoid Communication</strong></p>						
				<p>Toronto, Canada
				<br>Oct. 15, 2019</p> 
				
				<p><strong>Room TBD</strong></p> 

				
				<!--
				<br>
				<ul class="actions">
					<li><a href="photos.html" class="button big special bighero-font">Photos</a></li>
				</ul>
				-->
				


				<!--
				<div id="baymax"><img style="height: 100%;" src="images/baymax/baymax.png" /></div>
				-->


			</section>





		<div id="redbar"></div>
		<!--<span class="anchor" id="call"></span>-->
		<span class="anchor" id="objectives"></span>
		<section id="one" class="wrapper style2">

			<div class="inner">
				<h2><strong>Objectives</strong></h2>
				<!--<h2><strong>Call For Contributions</strong></h2>-->
				<p>We are excited to announce the 5th workshop titled <i>Can we build Baymax?</i> Part V. Since the first workshop was organized in 2015, our workshop series has taken place at the IEEE-RAS International Conference on Humanoid Robots <a target="_blank" href="http://humanoids2019.loria.fr/">(Humanoids 2019)</a> every year. Baymax is a humanoid character in the Disney feature animation Big Hero 6. It is a healthcare robot with an inflatable body, capable of walking, bumping into surrounding objects, learning motions and physically interacting with people. However, in the real world, it is not easy to build such a robot. In the previous workshops, we have discussed topics on mechanisms and structure, sensors, protection, control, soft robot fabrication, fail-safe systems and learning for humanoid robots. As a continuation of the discussion, this workshop will bring together researchers looking for paths toward seamless communication between humans and humanoid robots like Baymax. In particular, we will tackle challenges in rendering and interpreting diverse types of interactions from hardware and software points of view including but not limited to gestures, touching and hugging, facial expressions, speech, body language, and eye contact.</p>


				<p>We invite you to contribute and to participate in this workshop.</p>

				<br>
 
				<strong>The workshop's topics include, but are not limited to:</strong>
				<ul>
					<li>Cognitive sciences for social robots</li>
					<li>Multi-modal human-robot communication</li>
					<li>Socially assistive robots to improve quality of life</li>
					<li>Human monitoring and intention recognition</li>
					<li>Expressive robot hardware</li>
					<li>Humanoids for interactive medical and health care</li>
					<li>Social and ethical issues</li>
				</ul>

				<br>

				<strong>Confirmed Speakers:</strong>
				<ul>

					<li><a href="#anchor_alspach">Alex Alspach</a>, Toyota Research Institute, USA</li> 
					
					<li><a href="#anchor_cheng">Gordon Cheng</a>, Technical University of Munich, Germany</li> 
					
					<li><a href="#anchor_hanson">David Hanson</a>, Hanson Robotics, Hong Kong</li>
					
					<li><a href="#anchor_ivaldi">Serena Ivaldi</a>, INRIA Nancy Grand-Est, France</li>

					<li><a href="#anchor_kim">Joohyung Kim</a>, Disney Research, USA</li>

					<li><a href="#anchor_chpark">Chung Hyuk Park</a>, The George Washington University, USA</li>
					
					<li><a href="#anchor_hwpark">Hae Won Park</a>, MIT Media Lab, USA</li>
					
					<li><a href="#anchor_righetti">Ludovic Righetti</a>, New York University, USA & Max-Planck Institute, Germany</li>
					
					<li><a href="#anchor_yamane">Katsu Yamane</a>, Honda Research Institute, USA</li>





					<!--
					<li>Yohei Kakiuchi (University of Tokyo, Japan)</li>
					<li>Christopher Atkeson (Carnegie Mellon University, USA)</li>
					<li>Hiroshi Kaminaga (AIST, Japan)</li>
					<li>Abderrahmane Kheddar, (CNRS-AIST, France)</li>
					<li>Joohyung Kim (Disney Research Los Angeles, USA)</li>
					<li>Jinoh Lee (Italian Institute of Technology, Italy)</li>
					<li>Nikos Tsagarakis (Italian Institute of Technology, Italy)</li>
					<li>Katsu Yamane (Honda Research Institute, USA)</li> 
					<li>Shihao Wang (Duke University, USA)</li>
					<li>Joohyung Kim (Disney Research Los Angeles, USA)</li>
					<li>Alex Alspach (Toyota Research Institute, USA)</li>	
					-->
				</ul>

				<!--
				<strong>Tentative Speakers:</strong>
				<ul>
					<li><a href="#anchor_alspach">Alex Alspach</a>, Toyota Research Institute, USA</li>
						
				</ul>
				-->		

				<br>		

				<strong>Previous Workshops:</strong>
				<ul>

					<li>2018: <a target="_blank" href="http://www.cs.cmu.edu/~cga/humanoids18workshop/ ">Fail-Safe HW & SW and Learning in Humanoid Robots</a></li>
					
					<li>2017: <a target="_blank" href="http://www.cs.cmu.edu/~cga/humanoids17workshop/ ">Design and Control for Soft Human-Robot Interaction</a></li>

					<li>2016: <a target="_blank" href="http://www.cs.cmu.edu/~cga/humanoids16workshop/ ">Making Hard Robots Soft: Sensors, Skin and Airbags</a></li>
					
					<li>2015: <a target="_blank" href="http://www.cs.cmu.edu/~cga/humanoids15workshop/">Soft Robotics and Safe Human-Robot Interaction in Humanoids</a></li>
					
				</ul>

				
				<!--

				<br>
				<h2><strong>Contributions:</strong></h2>

				<p>The workshop will gladly host contributions including short talks, posters, or any others proposed.</p>
				<br>



				<strong>Important dates:</strong>
				<ul>	
					
					<li>Sept. X, 2019: Submissions due</li>

					<li>Sept. X, 2019: Acceptance notification</li>

					<li>Sept. X, 2019: Short Talk Session Notification</li>
					
					
					
					<li><font color="red">Oct. XX, 2019:</font> Short Talk Session Deadline Extended!
					
					
					<li>Oct. 15, 2019: Can we build Baymax? Workshop</li>
				</ul>


				<br>
				<h2><strong>Abstract Submission</strong></h2>

				<p>The workshop will host a session of short talks. The presenters in this session will give 15 minute talks.</p>
 
				<p>To participate, please submit an abstract (1-2 pages, double-column, PDF) via email to <br>
					Joohyung Kim ( joohyung.kim at disney dot com ) or <br>
					Jinoh Lee ( jinoh.lee at iit dot it )</p>


				<p>Submission templates: 
				<a target="_blank" href="http://ras.papercept.net/conferences/support/tex.php">LaTeX</a>, <a target="_blank" href="http://ras.papercept.net/conferences/support/word.php">MS Word</a></p>

				-->
				
			</div>
		</section>



		<div id="redbar"></div>




		<!-- Two -->
		<span class="anchor" id="schedule"></span>
		<section id="two" class="wrapper style1">
			<div class="inner">

				<h2><strong>Workshop Schedule</strong></h2>
				
				<table class="schedule" width="100%" border="0" cellspacing="0" cellpadding="0">
					<tbody>

						<tr>
							<td class="sched_time">08:50 - 09:00</td>
							<td class="sched_speaker">Welcome and Introduction</td>
						</tr>

						<tr>
							<td class="sched_time">09:00 - 09:30</td>
							<td class="sched_speaker">Katsu Yamane, Honda Research Institute, USA
							<div class="talk-title">Empathetic Physical Interaction</div>


							  	<div class="text-content short-text">
							  	<br>
	        					<p>Physical interactions using the body play an important role in human-human interactions by allowing the exchange of subtle information that is difficult to describe in words, e.g. comfort, preference, intention, and emotion. Robots working closely with humans have to understand, utilize and express such information in order to effectively interact with humans. The goal of empathetic physical interaction is to realize human-centered physical support where the robot uses its body as a medium for exchanging subtle information with the human partner, and adapts its behavior based on the information to improve the human perception and, ultimately, overall performance of physical support. This talk will introduce two related ongoing projects at Honda Research Institute USA: perception of pedestrian avoidance behavior of a mobile robot, and modeling of intimate social interactions of a humanoid robot.</p>
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>

							</td>
						</tr>

						<tr>
							<td class="sched_time">09:30 - 10:00</td>
							<td class="sched_speaker">David Hanson, Hanson Robotics, Hong Kong
								<div class="talk-title">Art meets Artificial Intelligence, or Why Humanizing Robots Can Be Useful and Cool</div>
		
				
							  	<div class="text-content short-text">
							  	<br>
	        					<p>Most robots and AI today are designed to be non-humanlike, and certainly for many uses they don't need to be humanoid. However, for key applications such as the arts, intuitive social interfaces for AI agents, certain kinds of therapy, and for scientific investigation of human behavior, humanlike robots can be very useful. This presentation covers the tech, arts, and history of Hanson robots, including transdisciplinary collaboration among artists, robotics & AI engineers, manufacturing, business development, and social sciences. By diversifying the creative landscape of robotics, bringing domains of engineering together with narrative and figurative arts, philosophy, ethics, biosciences, and AI, we hope to achieve a better toolkit to discover what's best in humanity, and to empower intelligent machines to work with people better. Investigating new forms of robots as works of art may also challenge our preconceptions and allow for surprise and wonder. Furthermore, making AI embodied and humanlike may facilitate a path of co-evolution, leading towards machines who may someday grow to become true friends to humanity, as trusted allies rather than mere slaves. Maybe, humanizing our machines will realize a more stable world with growing benefits for all sentient beings.</p>
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>


							    

							</td>
						</tr>

						<tr>
							<td class="sched_time">10:00 - 10:30</td>
							<td class="sched_speaker">Gordon Cheng, Technical University of Munich, Germany
								<div class="talk-title">TBD</div>
							</td>
						</tr>

						<tr>
							<td class="sched_time">10:30 - 11:00</td>
							<td class="sched_speaker">Coffee Break (Lobby)
							</td>
						</tr>						

						<tr>
							<td class="sched_time">11:00 - 11:30</td>
							<td class="sched_speaker">Serena Ivaldi, INRIA Nancy Grand-Est, France
								<div class="talk-title">Social and physical interaction with a humanoid: Lessons learned with the iCub</div>	

							  	<div class="text-content short-text">
							  	<br>
	        					<p>In this talk I will overview our recent human-humanoid interaction experiments with the iCub humanoid and discuss our findings. We studied social and physical interaction in a collaborative assembly scenario to study engagement and relation to individual factors. We studied how to use these signals for predicting intention in collaborative scenarios, which led us to a multimodal intention prediction framework based on probabilistic movement primitives. Finally, we studied trust in human-humanoid interaction with a shared decision protocol, which unveiled the people’s negative trusting attitude towards the robot. I will conclude with our current perspectives in whole-body collaboration.</p>
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>

							</td>
						</tr>

						<tr>
							<td class="sched_time">11:30 - 12:00</td>
							<td class="sched_speaker">Chung Hyuk Park, George Washington University, USA
								<div class="talk-title">Empathetic Agent and Interactions with Children with ASD</div>

							  	<div class="text-content short-text">
							  	<br>
	        					<p>Socially assistive robots (SARs) and their application for interventions for children with autism spectrum disorder (ASD) have been actively researched and widely used in special education and clinical settings. Going further from their utilization as learning aids and research platforms, this talk will address the aspects of empathy and emotion regulation (ER) for SARs, which are important mechanisms to be implemented in interventions since the empathy and ER impairments are underlying factors for many atypicalities manifested in ASD. We will discuss the design of our empathetic robotic agent, including the design and the algorithmic model to provide dynamic ER capabilities. In addition, we will describe a user study that evaluates the ER capabilities of an emotionally expressive empathetic agent as well as its capability to prime higher social engagement in a user.</p>
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>


							</td>
						</tr>


						<tr>
							<td class="sched_time">12:00 - 12:30</td>
							<td class="sched_speaker">Hae Won Park, MIT Media Lab, USA
								<div class="talk-title">Socio-Emotive Intelligence for Long-term Human-Robot Interaction</div>

							  	<div class="text-content short-text">
							  	<br>
	        					<p>In this talk, I’d like to engage our community to question whether robots need socio-emotive intelligence. To answer this question though, we need to first think about a new dimension of evaluating AI algorithms and systems that we build - measuring their impact on people’s lives in the real-world contexts. I will highlight a number of provocative research findings from our recent long-term deployment of social robots in schools, homes, and older adult living communities. We employ an affective reinforcement learning approach to personalize robot’s actions to modulate each user’s engagement and maximize the interaction benefit. The robot observes users’ verbal and nonverbal affective cues to understand the user state and to receive feedback on its actions. Our results show that the interaction with a robot companion influences users’ beliefs, learning, and how they interact with others. The affective personalization boosts these effects and helps sustain long-term engagement. During our deployment studies, we observed that people treat and interact with artificial agents as social partners and catalysts. We also learned that the effect of the interaction strongly correlates to the social relational bonding the user has built with the robot. So, to answer the question “does a robot need socio-emotive intelligence,” I argue that we should only draw conclusions based on what impact it has on the people living with it -  is it helping us flourish in the direction that we want to thrive?</p>
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>


							</td>
						</tr>



						<tr>
							<td class="sched_time">12:30 - 14:00</td>
							<td class="sched_speaker">Lunch
							</td>
						</tr>


						<tr>
							<td class="sched_time">14:00 - 14:30</td>
							<td class="sched_speaker">Ludovic Righetti, New York University, USA & Max-Planck Institute, Germany
								<div class="talk-title">What can go wrong when robots physically interact with humans? An ethical and technical perspective</div>

							  	<div class="text-content short-text">
							  	<br>
	        					<p>The ability to safely physically interact with humans is one of the most exciting features of Baymax. This presentation will tackle two drastically different, yet, inseparable issues when discussing robots that interact with humans: the technical problem of safe physical interaction and the ethical issues inherent to robots making decisions that impact us. The first part of the presentation will present our research related to the control of contact interactions, using both optimal control and reinforcement learning and highlight some of the current challenges one faces when creating safe physical interactions. In the second part of the talk, we will discuss some issues that can arise when robots interact with humans and make decisions that have an impact on how humans receive a service or health care support. We will give an overview of concerns associated to bias in machine learning that can lead to discriminatory behaviors and explain how this impacts robotics. Then we will give some possible research directions on how to tackle these issues to create safe robot companions that can benefit everyone.</p>
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>


							</td>
						</tr>

						<tr>
							<td class="sched_time">14:30 - 15:00</td>
							<td class="sched_speaker">Alex Alspach, Toyota Research Institute, USA
								<div class="talk-title">Tactile sensing bubbles for interaction</div>

							</td>
						</tr>	


						<tr>
							<td class="sched_time">15:00 - 15:30</td>
							<td class="sched_speaker">Joohyung Kim, Disney Research, USA
								<div class="talk-title">Robots inspired by animation characters</div>


							  	<div class="text-content short-text">
							  	<br>
	        					<p>Animated characters often have interesting and unique motions, configurations and abilities. Animators mostly base these creatures on nature, including humans, and augment them with their imagination. As technology advances, some of these features become implementable in real robots. In this talk, I will present our efforts at Disney Research to make robots that capture these interesting features from animation characters.</p>
	    						</div>
							    <div class="show-more">
							        <a href="#">Abstract</a>
							    </div>


							</td>
						</tr>	


						<tr>
							<td class="sched_time">15:30 - 16:00</td>
							<td class="sched_speaker">Coffee Break (Lobby)
							</td>
						</tr>	



						<tr>
							<td class="sched_time">16:00 - 16:30</td>
							<td class="sched_speaker">Communicate with Speakers</td>
						</tr>

						<tr>
							<td class="sched_time">16:30 - 17:30</td>
							<td class="sched_speaker">Open discussion and Closing</td>
						</tr>

						<tr>
							<td class="sched_time">18:00 - </td>
							<td class="sched_speaker">Welcome Reception and Late Breaking Reports</td>
						</tr>
						
					</tbody>
					
				</table>
				



			</div>
		</section>		

		<!-- Three -->
		<span class="anchor" id="speakers"></span>
		<section id="three" class="wrapper style2">
			<div class="inner">

				<h2><strong>Speakers</strong></h2>


				<ul>
					<li><a href="#anchor_alspach">Alex Alspach</a>, Toyota Research Institute, USA</li> 
					<li><a href="#anchor_cheng">Gordon Cheng</a>, Technical University of Munich</li>
					<li><a href="#anchor_hanson">David Hanson</a>, Hanson Robotics, Hong Kong</li>
					<li><a href="#anchor_ivaldi">Serena Ivaldi</a>, INRIA Nancy Grand-Est, France</li>
					<li><a href="#anchor_kim">Joohyung Kim</a>, Disney Research, USA</li>
					<li><a href="#anchor_chpark">Chung Hyuk Park</a>, The George Washington University, USA</li>
					<li><a href="#anchor_hwpark">Hae Won Park</a>, MIT Media Lab, USA</li>
					<li><a href="#anchor_righetti">Ludovic Righetti</a>, New York University, USA & Max-Planck Institute, Germany</li>
					<li><a href="#anchor_yamane">Katsu Yamane</a>, Honda Research Institute USA</li>

				</ul>

				<br>


				<span class="anchor2" id="anchor_cheng"></span>
				<article class="feature left">
					<span class="image"><img src="images/speakers/web/Cheng_Gordon.jpg" alt="" /></span>
					<div class="content">

						<h2>Gordon Cheng</h2>

						<p>Gordon Cheng holds the Chair of Cognitive Systems with regular teaching activities and lectures. He is Founder and Director of Institute for Cognitive Systems, Faculty of Electrical and Computer Engineering at Technical University of Munich, Munich/Germany. He is also the coordinator of the CoC for Neuro-Engineering - Center of Competence Neuro-Engineering in the Department of Electrical and Computer Engineering.</p>
						
						<p>Formerly, he was the Head of the Department of Humanoid Robotics and Computational Neuroscience, ATR Computational Neuroscience Laboratories, Kyoto, Japan. He was the Group Leader for the newly initiated JST International Cooperative Research Project (ICORP), Computational Brain. He has also been designated as a Project Leader/Research Expert for National Institute of Information and Communications Technology (NICT) of Japan. He is also involved (as an adviser and as an associated partner) in a number of major European Union Projects.</p>

						<p>Over the past ten years Gordon Cheng has been the co-inventor of approximately 20 patents and is the author of approximately 250 technical publications, proceedings, editorials and book chapters.</p>

					</div>
				</article>	



				<span class="anchor2" id="anchor_hanson"></span>
				<article class="feature left">
					<span class="image"><img src="images/speakers/web/Hanson_David.jpg" alt="" /></span>
					<div class="content">

						<h2>David Hanson</h2>

						<p>David Hanson develops robots that are widely regarded as the world’s most human-like in appearance, in a lifelong quest to create true living, caring machines. To accomplish these goals, Hanson integrates figurative arts with cognitive science and robotics engineering, inventions novel skin materials, facial expression mechanisms, and collaborative developments in AI, within humanoid artworks like Sophia the robot, which can engage people in naturalistic face-to-face conversations and currently serve in AI research, education, therapy, and other uses.</p>

						<p>Hanson worked as a Walt Disney Imagineer, both a sculptor and a technical consultant in robotics, and later founded Hanson Robotics. As a researcher, Hanson published dozens of papers in materials science, artificial intelligence, cognitive science, and robotics journals — including SPIE, IEEE, the International Journal of Cognitive Science, IROS, AAAI, AI magazine and more. He wrote two books including “Humanizing Robots” and received several patents. Hanson was featured in the New York Times, Popular Science, Scientific American, WIRED, BBC and CNN. He also received earned awards from NASA, NSF, Tech Titans’ Innovator of the Year, RISD, Cooper Hewitt Design Triennial, and the co-received the 2005 AAAI first place prize for open interaction of an AI system. Hanson holds a Ph.D. in Interactive Arts and Technology from the University of Texas at Dallas, and a BFA in film Animation video from the Rhode Island School of Design.</p>

					</div>
				</article>


				<span class="anchor2" id="anchor_ivaldi"></span>
				<article class="feature left">
					<span class="image"><img src="images/speakers/web/Ivaldi_Serena.jpg" alt="" /></span>
					<div class="content">

						<h2>Serena Ivaldi</h2>

						<p>Serena Ivaldi is a tenured research scientist at Inria, leading the humanoid and human-robot interaction activities of the Team Larsen in Inria Nancy, France. She earned her Ph.D. in Humanoid Technologies in 2011 at the Italian Institute of Technology. Prior to joining Inria, she was post-doctoral researcher in UPMC in Paris, France, then at the University of Darmstadt, Germany. She was PI of the EU projects CoDyCo (FP7); she is currently PI of the EU projects AnDy (H2020) and Heap (CHIST-ERA). She is also involved in the French ANR project Flying CoWorker. Her research is focused on humanoid robotics and human-robot collaboration, using machine learning to improve the control, prediction and interaction skills of robots. She strongly believes in user evaluation, i.e., making potential end-users evaluate the robotics technologies to improve usability, trust and acceptance.</p>

					</div>
				</article>				



				<span class="anchor2" id="anchor_chpark"></span>
				<article class="feature left">
					<span class="image"><img src="images/speakers/web/Park_ChungHyuk.jpg" alt="" /></span>
					<div class="content">

						<h2>Chung Hyuk Park</h2>

						<p>Dr. Chung Hyuk Park is an assistant professor in the Department of Biomedical Engineering (BME) in the School of Engineering and Applied Science (SEAS) at The George Washington University (GW). Dr. Park directs the Assistive Robotics and Tele-Medicine (ART-Med) Lab in GW where he studies the collaborative innovation between human intelligence and robotic technology, integrating human-robot interaction, machine learning, computer vision, haptics, and telepresence robotics. The current and future research topics are focused on the following three main themes: Multi-modal human-robot interaction and robotic assistance for individuals with disabilities or special needs, Robotic learning and humanized intelligence, and Tele-medical robotic assistance. He was the lead-PI for a NRI-NIH project (#R01 HD082914) and a recipient of a NSF Early Career award on socially assistive robotics for individuals with Autism Spectrum Disorder (ASD). He received his Ph.D. in Electrical and Computer Engineering from the Georgia Institute of Technology in 2012 and M.S. in Electrical Engineering and Computer Science and B.S. in Electrical Engineering from Seoul National University in 2002 and 2000, respectively.</p>

					</div>
				</article>



				<span class="anchor2" id="anchor_hwpark"></span>
				<article class="feature left">
					<span class="image"><img src="images/speakers/web/Park_Hae_Won2.jpg" alt="" /></span>
					<div class="content">

						<h2>Hae Won Park</h2>

						<p>Hae Won Park is a Research Scientist at MIT Media Lab and a Principal Investigator of the Social Robot Companions Program. Her research focuses on socio-emotive AI and personalization of social robots that support long-term interaction and relationship between users and their robot companions. Her work spans a range of applications including education for young children and wellbeing benefits for older adults. Her research has been published at top robotics and AI venues and has received awards for best paper (HRI 2017), innovative robot applications (ICRA 2013), and pecha-kucha presentation (ICRA 2014). Hae Won received her PhD from Georgia Tech in 2014, at which time she also co-founded Zyrobotics, an assistive education robotics startup that was recognized as the best 2015 US robotics startup by Robohub and was the finalist of the Intel Innovation Award.</p>

					</div>
				</article>


				<span class="anchor2" id="anchor_righetti"></span>
				<article class="feature left">
					<span class="image"><img src="images/speakers/web/Righetti_Ludovic.jpg" alt="" /></span>
					<div class="content">

						<h2>Ludovic Righetti</h2>

						<p>Ludovic Righetti is an Associate Professor in the Electrical and Computer Engineering Department and in the Mechanical and Aerospace Engineering Department at the Tandon School of Engineering of New York University and a Senior Researcher at the Max-Planck Institute for Intelligent Systems (MPI-IS) in Tübingen, Germany.</p>

						<p>He leads the Machines in Motion Laboratory, where his research focuses on the planning and control of movements for autonomous robots, with a special emphasis on legged locomotion and manipulation. He is more broadly interested in questions at the intersection of decision making, automatic control, optimization, applied dynamical systems and machine learning and their application to physical systems.</p>

						<p>He studied at the Ecole Polytechnique Fédérale de Lausanne (Switzerland) where he received an engineering diploma in Computer Science (eq. M.Sc.) in 2004 and a Doctorate in Science in 2008 under the supervision of Professor Auke Ijspeert. Between March 2009 and August 2012, he was a postdoctoral fellow at the Computational Learning and Motor Control Lab with Professor Stefan Schaal (University of Southern California). In September 2012 he started the Movement Generation and Control Group at the Max-Planck Institute for Intelligent Systems in Tübingen, Germany where he became a W2 Independent Research Group Leader in September 2015. He moved to New York University in September 2017.</p>

						<p>He has received several awards, most notably the 2010 Georges Giralt PhD Award given by the European Robotics Research Network (EURON) for the best robotics thesis in Europe, the 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) Best Paper Award, the 2016 IEEE Robotics and Automation Society Early Career Award and the 2016 Heinz Maier-Leibnitz Prize from the German Research Foundation.</p>

					</div>
				</article>



			</div>
		</section>
		




		<!-- Four -->
		<span class="anchor" id="organizers"></span>
		<section id="four" class="wrapper style1">
			<div class="inner">

				<h2><strong>Organizers</strong></h2>

				
				<ul>
					<li><a href="#anchor_atkeson">Chris Atkeson</a>, Carnegie Mellon University</li>
					<li><a href="#anchor_kim">Joohyung Kim</a>, Disney Research</li>
					<li><a href="#anchor_lee">Jinoh Lee</a>, Italian Institute of Technology</li>
					<li><a href="#anchor_yamane">Katsu Yamane</a>, Honda Research Institute</li>
					<li><a href="#anchor_alspach">Alex Alspach</a>, Toyota Research Institute</li>
				</ul>

				<br>

				<span class="anchor2" id="anchor_atkeson"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Atkeson_Chris.jpg" alt="" /></span>
					<div class="content">

						<h2>Christopher G. Atkeson</h2>

						<!--
						<p>I am a Professor in the Robotics Institute and Human-Computer Interaction Institute at CMU. I received the M.S. degree in Applied Mathematics (Computer Science) from Harvard University and the Ph.D. degree in Brain and Cognitive Science from M.I.T. I joined the M.I.T. faculty in 1986, moved to the Georgia Institute of Technology College of Computing in 1994, and moved to CMU in 2000. I have received an NSF Presidential Young Investigator Award, a Sloan Research Fellowship, and a Teaching Award from the MIT Graduate Student Council.</p>
						-->



						<p>I am a Professor in the Robotics Institute and Human-Computer Interaction Institute at Carnegie Mellon University. My life goal is to fulfill the science fiction vision of machines that achieve human levels of competence in perceiving, thinking, and acting. A more narrow technical goal is to understand how to get machines to generate and perceive human behavior. I use two complementary approaches, exploring humanoid robotics and human aware environments. Building humanoid robots tests our understanding of how to generate human-like behavior, and exposes the gaps and failures in current approaches.</p>



						<p><a target="_blank" href="http://www.build-baymax.org">build-baymax.org</a></p>

					</div>
				</article>

				<!--
				<span class="anchor2" id="anchor_kaminaga"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Kaminaga_Hiroshi.jpg" alt="" /></span>
					<div class="content">

						<h2>Hiroshi Kaminaga</h2>

						<p>Hiroshi Kaminaga is a senior researcher in AIST, Japan.  He received his bachelors degree in 1997 from Sophia University and masters degree in 1999 from Kyoto University  for mechanical engineering.  He received his doctorate in information science and technology from The University of Tokyo in 2009.  He worked as an R&D engineer from 1999 to 2002 in Hewlett-Packard Japan and from 2002 to 2005 in a robotics startup company, ZMP Inc.  He started his academic career as a research fellow of Japan Society for the Promotion of Science in 2009, as an assistant professor of The University of Tokyo from 2009.  He has been in his current position in AIST (National Institute of Advanced Industrial Science and Technology) since 2017.</p>

					</div>
				</article>	
				-->


				<span class="anchor2" id="anchor_kim"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Kim_Joohyung.jpg" alt="" /></span>
					<div class="content">

						<h2>Joohyung Kim</h2>

						<p>Joohyung Kim is currently a Research Scientist in Disney Research, LA. His research interests include implementation of robots based on animation characters, soft human-robot interaction, balancing and walking control for humanoid robots and novel mechanisms for legged locomotion. He received BSE and Ph.D. degrees in Electrical Engineering and Computer Science from Seoul National University, Korea, in 2001 and 2012. Prior to joining Disney Research, he was a postdoctoral fellow in Robotics Institute of Carnegie Mellon University for DARPA Robotics Challenge in 2013. From 2009 to 2012 he was a senior engineer in Samsung Electronics, Korea, developing biped walking controllers for humanoid robots.</p>

					</div>
				</article>	

				<span class="anchor2" id="anchor_lee"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Lee_Jinoh2.jpg" alt="" /></span>
					<div class="content">

						<h2>Jinoh Lee</h2>

						<p>Jinoh Lee is a Research Scientist in the Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT). He received his B.Sc. degree in Mechanical Engineering from Hanyang University, Seoul, South Korea, in 2003 (awarded Summa Cum Laude, Top 2%) and his M.Sc. and Ph.D. degrees in Mechanical Engineering from Korea Advanced Institute of Science and Technology (KAIST) in Daejeon, South Korea in 2012. Since 2012, he has joined IIT as a postdoctoral researcher and has been awarded a competitive grant from the National Research Foundation (NRF) of the Korean Government titled 'Fostering Next Generation Researchers Program' (2013-2014). He has been involved in projects such as WALK-MAN (Whole-body Adaptive Locomotion and Manipulation), participated in the DARPA Robotics Challenge (DRC) Finals, where contributions were made to develop various manipulation skills on the humanoid. His research has primarily focused on control of compliant multi-DoF robotic systems and the dexterous and reactive manipulation of humanoids and bimanual robots with multiple contacts.</p>

					</div>
				</article>

				<span class="anchor2" id="anchor_yamane"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Yamane_Katsu.jpg" alt="" /></span>
					<div class="content">

						<h2>Katsu Yamane</h2>

						<p>Dr. Katsu Yamane is a Senior Scientist at Honda Research Institute USA. He received his B.S., M.S., and Ph.D. degrees in Mechanical Engineering in 1997, 1999, and 2002 respectively from the University of Tokyo, Japan. Prior to joining Honda in 2018, he was a Senior Research Scientist at Disney Research, an Associate Professor at the University of Tokyo, and a postdoctoral fellow at Carnegie Mellon University. Dr. Yamane is a recipient of King-Sun Fu Best Transactions Paper Award and Early Academic Career Award from IEEE Robotics and Automation Society, and Young Scientist Award from Ministry of Education, Japan. His research interests include humanoid robot control and motion synthesis, physical human-robot interaction, character animation, and human motion simulation.</p>

					</div>
				</article>	

				<span class="anchor2" id="anchor_alspach"></span>
				<article class="feature left">
					<span class="image object-fit_contain"><img src="images/speakers/web/Alspach_Alex.jpg" alt="" /></span>
					<div class="content">

						<h2>Alex Alspach</h2>

						<p>Alex designs and builds soft systems for sensing and manipulation at Toyota Research Institute (TRI). He earned his master's degree at Drexel University with time spent in the Drexel Autonomous Systems Lab (DASL) and KAIST's HuboLab. After graduating, Alex spent two years at SimLab in Korea developing and marketing tools for manipulation research. While there, he also worked with a production company to develop artists' tools for animating complex, synchronized industrial robot motions. Prior to joining TRI, Alex developed soft <i>huggable</i> robots and various other systems at Disney Research with Joohyung and Katsu!</p>

					</div>
				</article>	

				<!-- Logos -->
				<div class="logo_container2">
					<center>
					<img class="org_logos2 object-fit_contain" src="images/logos/web/logos5.png" alt="" />
					</center>
				</div>

				
			</div>
		</section>

		<!-- Five -->
		<span class="anchor" id="links"></span>
		<section id="five" class="wrapper style2">
			<div class="inner">

				<h2><strong>Related Links</strong></h2>

				
				<ul>
					
					<li><a target="_blank" href="http://humanoids2019.loria.fr/">Humanoids 2019</a></li>

					<li><a target="_blank" href="http://www.cs.cmu.edu/~cga/humanoids18workshop/">Can we build Baymax? Humanoids 2018</a></li>

					<li><a target="_blank" href="http://www.cs.cmu.edu/~cga/humanoids17workshop/">Can we build Baymax? Humanoids 2017</a></li>

					<li><a target="_blank" href="http://www.cs.cmu.edu/~cga/humanoids16workshop/">Can we build Baymax? Humanoids 2016</a></li>

					<li><a target="_blank" href="http://www.cs.cmu.edu/~cga/humanoids15workshop/">Can we build Baymax? Humanoids 2015</a></li>

					<li><a target="_blank" href="http://www.build-baymax.org">Build-Baymax.org</a></li>
				</ul>
				
			</div>
		</section>

		<!-- Five -->
		<span class="anchor" id="contact"></span>
		<section id="five" class="wrapper style1">
			<div class="inner">

				<h2><strong>Contact</strong></h2>

				
				<ul>
					<li>Joohyung Kim ( joohyung.kim at disney dot com )</li>
					<li>Jinoh Lee ( jinoh.lee at iit dot it )</li>
				</ul>
				
			</div>
		</section>		






		<!-- Footer -->
		<footer id="footer">
			<div class="inner">
				<p><a target="_blank" href="http://alexalspach.com">Designed by Alex Alspach. 2019</a></p>
				
			</div>
		</footer>

		<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/skel.min.js"></script>
		<script src="assets/js/util.js"></script>
		<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
		<script src="assets/js/main.js"></script>


		<script>
			$(".show-more a").each(function() {
			    var $link = $(this);
			    var $content = $link.parent().prev("div.text-content");

			    console.log($link);

			    var visibleHeight = $content[0].clientHeight;
			    var actualHide = $content[0].scrollHeight - 1;

			    console.log(actualHide);
			    console.log(visibleHeight);

			    if (actualHide > visibleHeight) {
			        $link.show();
			    } else {
			        $link.hide();
			    }
			});

			$(".show-more a").on("click", function() {
			    var $link = $(this);
			    var $content = $link.parent().prev("div.text-content");
			    var linkText = $link.text();

			    $content.toggleClass("short-text, full-text");

			    $link.text(getShowLinkText(linkText));

			    return false;
			});

			function getShowLinkText(currentText) {
			    var newText = '';

			    if (currentText.toUpperCase() === "ABSTRACT") {
			        newText = "Hide Abstract";
			    } else {
			        newText = "Abstract";
			    }

			    return newText;
			}
		</script>




	</body>
</html>




